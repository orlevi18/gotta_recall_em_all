{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   queryid    docid  target        sim  \\\n",
      "0      119  1000015       1  10.733849   \n",
      "1      134  1000055      -1  26.299755   \n",
      "2       24  1000061      -1        NaN   \n",
      "3      111  1000075       1  11.925878   \n",
      "4      142  1000082      -1        NaN   \n",
      "\n",
      "                                             details          query  \\\n",
      "0  {'id': '1000015', 'title': 'kotobukiya art fx ...  batman statue   \n",
      "1  {'id': '1000055', 'title': 'us airways pilot t...   pilot helmet   \n",
      "2                                                NaN            NaN   \n",
      "3  {'id': '1000075', 'title': 'tigger bank walt d...    disney bank   \n",
      "4                                                NaN            NaN   \n",
      "\n",
      "                                            category  \\\n",
      "0                  Collectibles > Comics > Figurines   \n",
      "1   Collectibles > Transportation > Aviation > Ai...   \n",
      "2                                                NaN   \n",
      "3   Collectibles > Disneyana > Contemporary (1968...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                               title  \n",
      "0  kotobukiya art fx 1/6 batman statue  collectib...  \n",
      "1  us airways pilot teddy bear aviator bomber jac...  \n",
      "2                                                NaN  \n",
      "3  tigger bank walt disney winnie the pooh pvc co...  \n",
      "4                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "truth_file=open('ground_truth_pairs.tsv', 'r')\n",
    "truth=pd.read_csv(truth_file,header=None,names=['queryid','docid','target'],sep='\\t')\n",
    "truth_file.close()\n",
    "prediction_file=codecs.open('predictions_2_7.tsv', 'r',encoding='utf-8')\n",
    "prediction=pd.read_csv(prediction_file,header=None,names=['queryid','docid','sim','details','query','category','title'],sep='\\t')\n",
    "prediction_file.close()\n",
    "match_data=pd.merge(truth,prediction,on=['queryid','docid'],how='left')\n",
    "print(match_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data['prediction']=pd.notna(match_data['sim']).map({True: 1, False: -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   queryid    docid  target        sim  \\\n",
      "0      119  1000015       1  10.733849   \n",
      "1      134  1000055      -1  26.299755   \n",
      "2       24  1000061      -1        NaN   \n",
      "3      111  1000075       1  11.925878   \n",
      "4      142  1000082      -1        NaN   \n",
      "\n",
      "                                             details          query  \\\n",
      "0  {'id': '1000015', 'title': 'kotobukiya art fx ...  batman statue   \n",
      "1  {'id': '1000055', 'title': 'us airways pilot t...   pilot helmet   \n",
      "2                                                NaN            NaN   \n",
      "3  {'id': '1000075', 'title': 'tigger bank walt d...    disney bank   \n",
      "4                                                NaN            NaN   \n",
      "\n",
      "                                            category  \\\n",
      "0                  Collectibles > Comics > Figurines   \n",
      "1   Collectibles > Transportation > Aviation > Ai...   \n",
      "2                                                NaN   \n",
      "3   Collectibles > Disneyana > Contemporary (1968...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                               title  prediction  \n",
      "0  kotobukiya art fx 1/6 batman statue  collectib...           1  \n",
      "1  us airways pilot teddy bear aviator bomber jac...           1  \n",
      "2                                                NaN          -1  \n",
      "3  tigger bank walt disney winnie the pooh pvc co...           1  \n",
      "4                                                NaN          -1  \n"
     ]
    }
   ],
   "source": [
    "print(match_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cats={}\n",
    "for queryid in range(1,151):\n",
    "    query_cats[queryid]=dict()\n",
    "query_cats_sum={}\n",
    "for queryid in range(1,151):\n",
    "    query_cats_sum[queryid]=dict()\n",
    "counter=0\n",
    "for index,row in match_data.iterrows():\n",
    "    queryid=row['queryid']\n",
    "    cat=[x.strip() for x in row['category'].split(\">\")]\n",
    "    target=row['target']\n",
    "    #print(queryid, cat,target)\n",
    "    for j in range(2,len(cat)+1):\n",
    "        subcat=(\" > \".join(cat[0:j])).lower()\n",
    "        if subcat in query_cats[queryid]:\n",
    "            query_cats[queryid][subcat]+=1\n",
    "            if target==1:\n",
    "                query_cats_sum[queryid][subcat]+=1\n",
    "        else:\n",
    "            query_cats[queryid][subcat]=1\n",
    "            if target==1:\n",
    "                query_cats_sum[queryid][subcat]=1\n",
    "            else:\n",
    "                query_cats_sum[queryid][subcat]=0\n",
    "    counter=counter+1\n",
    "    #if counter>100000:\n",
    "    #    break\n",
    "\n",
    "\n",
    "query_cats_exclude={}\n",
    "for queryid in range(1,151):\n",
    "    query_cats_exclude[queryid]=set()\n",
    "for queryid in query_cats:\n",
    "    for subcat in query_cats[queryid]:\n",
    "        total=query_cats[queryid][subcat]\n",
    "        if total<5:\n",
    "            continue\n",
    "        relevant=query_cats_sum[queryid][subcat]\n",
    "        if relevant/total<0.5:\n",
    "            query_cats_exclude[queryid].add(subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collectibles > non-sport trading cards'}\n",
      "{'collectibles > comics > bronze age (1970-83) > war', 'collectibles > comics > copper age (1984-1991) > war'}\n",
      "set()\n",
      "set()\n",
      "{'collectibles > cultures & ethnicities > native american: us > 1935-now', 'collectibles > cultures & ethnicities > native american: us > 1935-now > sculptures', 'collectibles > cultures & ethnicities > native american: us'}\n",
      "{'collectibles > autographs', 'collectibles > militaria > ww ii (1939-45) > reproductions', 'collectibles > photographic images > contemporary (1940-now)', 'collectibles > advertising', 'collectibles > militaria > current militaria (2001-now) > original items > personal, field gear > pouches', 'collectibles > militaria > ww ii (1939-45) > reproductions > united states'}\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{'collectibles > disneyana > contemporary (1968-now) > pins, patches & buttons > disney characters & movies'}\n",
      "set()\n",
      "set()\n",
      "{'collectibles > postcards', 'collectibles > cultures & ethnicities > latin american > mexico > pottery'}\n",
      "{'collectibles > religion & spirituality > christianity > medals'}\n",
      "{'collectibles > radio, phonograph, tv, phone > phonographs, accessories', 'collectibles > decorative collectibles', 'collectibles > advertising > communication & utilities', 'collectibles > souvenirs & travel memorabilia > united states > new york', 'collectibles > souvenirs & travel memorabilia > united states', 'collectibles > radio, phonograph, tv, phone > radios > qsl cards', 'collectibles > advertising > merchandise & memorabilia', 'collectibles > advertising > communication & utilities > radio', 'collectibles > militaria', 'collectibles > radio, phonograph, tv, phone > radios > tube radios > pre-1930', 'collectibles > holiday & seasonal', 'collectibles > souvenirs & travel memorabilia', 'collectibles > advertising', 'collectibles > radio, phonograph, tv, phone > radios > parts & tubes'}\n",
      "set()\n",
      "{'collectibles > militaria > ww ii (1939-45) > original period items > united states', 'collectibles > advertising > merchandise & memorabilia > advertising-print > 1950-59', 'collectibles > radio, phonograph, tv, phone > radios', 'collectibles > advertising > communication & utilities', 'collectibles > militaria > ww ii (1939-45) > original period items', 'collectibles > militaria > ww ii (1939-45)', 'collectibles > advertising > household', 'collectibles > advertising > merchandise & memorabilia', 'collectibles > advertising > merchandise & memorabilia > advertising-print', 'collectibles > advertising > merchandise & memorabilia > advertising-print > 1940-49', 'collectibles > militaria', 'collectibles > advertising', 'collectibles > radio, phonograph, tv, phone > radios > manuals', 'collectibles > advertising > communication & utilities > radio'}\n",
      "{'collectibles > pens & writing instruments', 'collectibles > pens & writing instruments > pens > fountain pens', 'collectibles > pens & writing instruments > pens > ballpoint pens', 'collectibles > pens & writing instruments > pens'}\n",
      "{'collectibles > decorative collectibles > decorative collectible brands > lenox'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "for queryid in range(1,21):\n",
    "    print(query_cats_exclude[queryid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file=codecs.open('predictions_2_7.tsv', 'r',encoding='utf-8')\n",
    "prediction=pd.read_csv(prediction_file,header=None,names=['queryid','docid','sim','details','query','category','title'],sep='\\t')\n",
    "prediction_file.close()\n",
    "out_file=codecs.open('predictions_cats_exclude.tsv', 'w',encoding='utf-8')\n",
    "for index,row in prediction.iterrows():\n",
    "    queryid=row['queryid']\n",
    "    #if queryid>10:\n",
    "    #    break\n",
    "    docid=row['docid']\n",
    "    cat=[x.strip() for x in row['category'].split(\">\")]\n",
    "    to_exclude=0\n",
    "    for j in range(2,len(cat)+1):\n",
    "        subcat=(\" > \".join(cat[0:j])).lower()\n",
    "        if subcat in query_cats_exclude[queryid]:\n",
    "            to_exclude=1\n",
    "    if to_exclude:\n",
    "        out_file.write(str(queryid)+\"\\t\"+str(docid)+\"\\t\"+\"0\"+\"\\t\"+str(cat)+\"\\n\")\n",
    "    else:\n",
    "        out_file.write(str(queryid)+\"\\t\"+str(docid)+\"\\t\"+\"1\\n\")\n",
    "out_file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294961, 4)\n",
      "   queryid    docid  target  prediction details\n",
      "0      119  1000015       1           1     NaN\n",
      "1      134  1000055      -1           1     NaN\n",
      "2       24  1000061      -1          -1     NaN\n",
      "3      111  1000075       1           1     NaN\n",
      "4      142  1000082      -1          -1     NaN\n"
     ]
    }
   ],
   "source": [
    "new_prediction_file=codecs.open('predictions_cats_exclude.tsv', 'r',encoding='utf-8')\n",
    "new_prediction=pd.read_csv(new_prediction_file,header=None,names=['queryid','docid','prediction','details'],sep='\\t')\n",
    "new_prediction_file.close()\n",
    "new_prediction=new_prediction[new_prediction['prediction']==1.0]\n",
    "print(new_prediction.shape)\n",
    "new_match_data=pd.merge(truth,new_prediction,on=['queryid','docid'],how='left')\n",
    "new_match_data['prediction']=pd.notna(new_match_data['prediction']).map({True: 1, False: -1})\n",
    "print(new_match_data.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
